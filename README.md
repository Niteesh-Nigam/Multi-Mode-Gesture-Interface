# Hand Gesture Control Interface
# Introduction
This project leverages computer vision and hand tracking technologies to create an interactive interface that responds to hand gestures. It allows users to switch seamlessly between typing, resizing the keyboard, and controlling the cursor, making digital interaction more intuitive and engaging.

NOTE: This repository is not clean and has a lot of comments or features that needs to be recalibrated. 

# Features
Dynamic Interaction: Control your computer through natural hand movements.
Multiple Modes: Switch between typing, resizing the keyboard, and cursor control with simple gestures.
Real-time Feedback: Immediate response from the interface as gestures are recognized.
Customizable Layout: Adjust the size and position of the keyboard based on your comfort.

# Installation
Clone the repository to your local machine:

git clone https://github.com/Niteesh-Nigam/Multi-Mode-Gesture-Interface.git

# Prerequisites
Ensure you have Python installed, along with the following packages:

OpenCV
cvzone
numpy
pynput
pyautogui

# Operational Modes
Typing Mode: Allows you to type using an on-screen keyboard.
Resize Mode: Resize the on-screen keyboard by pinching and zooming.
Cursor Mode: Move the cursor and click using your fingers.
